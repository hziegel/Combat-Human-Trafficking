{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":35150,"databundleVersionId":4957097,"sourceType":"competition"},{"sourceId":3951115,"sourceType":"datasetVersion","datasetId":1027206},{"sourceId":96549317,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":33.821406,"end_time":"2025-03-19T20:06:22.564645","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-19T20:05:48.743239","version":"2.3.4"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\nInference notebook for [Hotel-ID starter - classification - traning](https://www.kaggle.com/code/michaln/hotel-id-starter-classification-traning)\n\n","metadata":{"id":"DAY5rHgTm7e8","papermill":{"duration":0.022235,"end_time":"2025-03-19T20:05:59.145418","exception":false,"start_time":"2025-03-19T20:05:59.123183","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Setup","metadata":{"papermill":{"duration":0.020644,"end_time":"2025-03-19T20:05:59.188756","exception":false,"start_time":"2025-03-19T20:05:59.168112","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:46:40.391325Z","iopub.execute_input":"2025-03-25T13:46:40.391640Z","iopub.status.idle":"2025-03-25T13:46:40.396394Z","shell.execute_reply.started":"2025-03-25T13:46:40.391618Z","shell.execute_reply":"2025-03-25T13:46:40.395166Z"},"executionInfo":{"elapsed":16271,"status":"ok","timestamp":1619310548121,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"alleged-legislation","outputId":"c6541e5f-ffb4-4609-d6c6-39784e6a07b1","papermill":{"duration":11.516733,"end_time":"2025-03-19T20:06:10.727259","exception":false,"start_time":"2025-03-19T20:05:59.210526","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports","metadata":{"id":"cZoSOL9Qm-Yr","papermill":{"duration":0.020585,"end_time":"2025-03-19T20:06:10.768628","exception":false,"start_time":"2025-03-19T20:06:10.748043","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport math","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-25T13:46:40.398433Z","iopub.execute_input":"2025-03-25T13:46:40.398839Z","iopub.status.idle":"2025-03-25T13:46:40.418148Z","shell.execute_reply.started":"2025-03-25T13:46:40.398797Z","shell.execute_reply":"2025-03-25T13:46:40.416969Z"},"executionInfo":{"elapsed":14459,"status":"ok","timestamp":1619310548121,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"expired-matter","papermill":{"duration":0.031884,"end_time":"2025-03-19T20:06:10.821888","exception":false,"start_time":"2025-03-19T20:06:10.790004","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image as pil_image\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:46:40.420527Z","iopub.execute_input":"2025-03-25T13:46:40.420874Z","iopub.status.idle":"2025-03-25T13:46:40.437424Z","shell.execute_reply.started":"2025-03-25T13:46:40.420833Z","shell.execute_reply":"2025-03-25T13:46:40.436265Z"},"executionInfo":{"elapsed":16003,"status":"ok","timestamp":1619310550014,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"extreme-problem","papermill":{"duration":0.028491,"end_time":"2025-03-19T20:06:10.871353","exception":false,"start_time":"2025-03-19T20:06:10.842862","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n!pip install dinov2  # if available","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:46:40.439223Z","iopub.execute_input":"2025-03-25T13:46:40.439551Z","iopub.status.idle":"2025-03-25T13:50:01.150290Z","shell.execute_reply.started":"2025-03-25T13:46:40.439525Z","shell.execute_reply":"2025-03-25T13:50:01.148992Z"},"executionInfo":{"elapsed":19672,"status":"ok","timestamp":1619310554099,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"angry-domain","papermill":{"duration":0.0289,"end_time":"2025-03-19T20:06:10.921250","exception":false,"start_time":"2025-03-19T20:06:10.892350","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setup & Imports\nimport sys\nimport os\nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom PIL import Image as pil_image\nfrom tqdm import tqdm\n\nimport albumentations as A\nimport albumentations.pytorch as APT\nimport torchvision.transforms as T\n\n# For reproducibility\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 42\nIMG_SIZE = 256\nseed_everything(SEED)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.151814Z","iopub.execute_input":"2025-03-25T13:50:01.152164Z","iopub.status.idle":"2025-03-25T13:50:01.162524Z","shell.execute_reply.started":"2025-03-25T13:50:01.152126Z","shell.execute_reply":"2025-03-25T13:50:01.161458Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Global","metadata":{"id":"0B00pe7mnBTj","papermill":{"duration":0.020614,"end_time":"2025-03-19T20:06:10.962719","exception":false,"start_time":"2025-03-19T20:06:10.942105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"SEED = 42\nIMG_SIZE = 256\n\nPROJECT_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\"\nTEST_DATA_FOLDER = PROJECT_FOLDER + \"test_images/\"","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.163705Z","iopub.execute_input":"2025-03-25T13:50:01.164044Z","iopub.status.idle":"2025-03-25T13:50:01.185708Z","shell.execute_reply.started":"2025-03-25T13:50:01.164004Z","shell.execute_reply":"2025-03-25T13:50:01.184283Z"},"executionInfo":{"elapsed":589,"status":"ok","timestamp":1619310979015,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"contained-brief","papermill":{"duration":0.029907,"end_time":"2025-03-19T20:06:11.013236","exception":false,"start_time":"2025-03-19T20:06:10.983329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir(PROJECT_FOLDER))","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.187101Z","iopub.execute_input":"2025-03-25T13:50:01.187530Z","iopub.status.idle":"2025-03-25T13:50:01.225147Z","shell.execute_reply.started":"2025-03-25T13:50:01.187491Z","shell.execute_reply":"2025-03-25T13:50:01.224021Z"},"executionInfo":{"elapsed":879,"status":"ok","timestamp":1619310979515,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"PZvmFng7ctO3","outputId":"dce0cc91-8e70-4acc-a0b8-6763ffffd5ca","papermill":{"duration":0.030579,"end_time":"2025-03-19T20:06:11.064812","exception":false,"start_time":"2025-03-19T20:06:11.034233","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Base transformation for inference (using Albumentations)\nbase_transform = A.Compose([\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.226149Z","iopub.execute_input":"2025-03-25T13:50:01.226445Z","iopub.status.idle":"2025-03-25T13:50:01.231534Z","shell.execute_reply.started":"2025-03-25T13:50:01.226419Z","shell.execute_reply":"2025-03-25T13:50:01.230448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pad_image(img):\n    w, h, c = np.shape(img)\n    if w > h:\n        pad = int((w - h) / 2)\n        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n    else:\n        pad = int((h - w) / 2)\n        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n    return img\n\ndef open_and_preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = pad_image(img)\n    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.235242Z","iopub.execute_input":"2025-03-25T13:50:01.235518Z","iopub.status.idle":"2025-03-25T13:50:01.259214Z","shell.execute_reply.started":"2025-03-25T13:50:01.235496Z","shell.execute_reply":"2025-03-25T13:50:01.258208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.261518Z","iopub.execute_input":"2025-03-25T13:50:01.261918Z","iopub.status.idle":"2025-03-25T13:50:01.279152Z","shell.execute_reply.started":"2025-03-25T13:50:01.261862Z","shell.execute_reply":"2025-03-25T13:50:01.278234Z"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1619310981653,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"eastern-content","papermill":{"duration":0.033715,"end_time":"2025-03-19T20:06:11.120143","exception":false,"start_time":"2025-03-19T20:06:11.086428","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset and transformations","metadata":{"id":"xaJKvvuKnW4k","papermill":{"duration":0.021835,"end_time":"2025-03-19T20:06:11.165014","exception":false,"start_time":"2025-03-19T20:06:11.143179","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import albumentations as A\nimport albumentations.pytorch as APT\nimport cv2 \n\nIMG_SIZE = 256\n\n# used for training dataset - augmentations and occlusions\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.75),\n    A.VerticalFlip(p=0.25),\n    A.ShiftScaleRotate(p=0.5, border_mode=cv2.BORDER_CONSTANT),\n    A.OpticalDistortion(p=0.25),\n    A.Perspective(p=0.25),\n    A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//4), # normal coarse dropout\n    \n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions in test data\n\n    A.RandomBrightnessContrast(p=0.75),\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# used for validation dataset - only occlusions\nval_transform = A.Compose([\n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.280418Z","iopub.execute_input":"2025-03-25T13:50:01.280849Z","iopub.status.idle":"2025-03-25T13:50:01.302782Z","shell.execute_reply.started":"2025-03-25T13:50:01.280797Z","shell.execute_reply":"2025-03-25T13:50:01.301658Z"},"executionInfo":{"elapsed":1519,"status":"ok","timestamp":1619310984075,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"revolutionary-membership","papermill":{"duration":2.720081,"end_time":"2025-03-19T20:06:13.908275","exception":false,"start_time":"2025-03-19T20:06:11.188194","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pad_image(img):\n    w, h, c = np.shape(img)\n    if w > h:\n        pad = int((w - h) / 2)\n        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n    else:\n        pad = int((h - w) / 2)\n        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n        \n    return img\n\n\ndef open_and_preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = pad_image(img)\n    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.303926Z","iopub.execute_input":"2025-03-25T13:50:01.304231Z","iopub.status.idle":"2025-03-25T13:50:01.326643Z","shell.execute_reply.started":"2025-03-25T13:50:01.304206Z","shell.execute_reply":"2025-03-25T13:50:01.325601Z"},"papermill":{"duration":0.031709,"end_time":"2025-03-19T20:06:13.961286","exception":false,"start_time":"2025-03-19T20:06:13.929577","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HotelImageDataset:\n    def __init__(self, data, transform=None, data_folder=\"train_images/\"):\n        self.data = data\n        self.data_folder = data_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        record = self.data.iloc[idx]\n        image_path = os.path.join(self.data_folder, record[\"image_id\"])\n        \n        image = np.array(open_and_preprocess_image(image_path)).astype(np.uint8)\n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed[\"image\"]\n        return {\"image\": image}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.327763Z","iopub.execute_input":"2025-03-25T13:50:01.328171Z","iopub.status.idle":"2025-03-25T13:50:01.348611Z","shell.execute_reply.started":"2025-03-25T13:50:01.328134Z","shell.execute_reply":"2025-03-25T13:50:01.347345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HotelImageDataset:\n    def __init__(self, data, transform=None, data_folder=\"train_images/\"):\n        self.data = data\n        self.data_folder = data_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        record = self.data.iloc[idx]\n        image_path = self.data_folder + record[\"image_id\"]\n        \n        image = np.array(open_and_preprocess_image(image_path)).astype(np.uint8)\n\n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed[\"image\"]\n        \n        return {\n            \"image\" : image,\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.349951Z","iopub.execute_input":"2025-03-25T13:50:01.350344Z","iopub.status.idle":"2025-03-25T13:50:01.374056Z","shell.execute_reply.started":"2025-03-25T13:50:01.350305Z","shell.execute_reply":"2025-03-25T13:50:01.373003Z"},"executionInfo":{"elapsed":1058,"status":"ok","timestamp":1619310984077,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"found-mouth","papermill":{"duration":0.040625,"end_time":"2025-03-19T20:06:14.022795","exception":false,"start_time":"2025-03-19T20:06:13.982170","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HotelIdDINOModel(nn.Module):\n    def __init__(self, n_classes, backbone_name=\"dinov2_vitl14\"):\n        \"\"\"\n        n_classes: Number of output classes (hotel IDs)\n        backbone_name: Name of the DINOv2 model as registered in timm\n        \"\"\"\n        super(HotelIdDINOModel, self).__init__()\n        # Create the backbone with pretrained weights\n        self.backbone = timm.create_model(backbone_name, pretrained=True)\n        # Remove the default classifier (if present)\n        self.backbone.reset_classifier(0)\n        # Attach a new classifier\n        self.classifier = nn.Linear(self.backbone.num_features, n_classes)\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        return self.classifier(features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.375251Z","iopub.execute_input":"2025-03-25T13:50:01.375671Z","iopub.status.idle":"2025-03-25T13:50:01.392007Z","shell.execute_reply.started":"2025-03-25T13:50:01.375633Z","shell.execute_reply":"2025-03-25T13:50:01.391005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{"id":"NMDM4PwPnced","papermill":{"duration":0.02149,"end_time":"2025-03-19T20:06:14.066209","exception":false,"start_time":"2025-03-19T20:06:14.044719","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def predict_tta(loader, model, n_matches=5, tta_transforms=3):\n    \"\"\"\n    Perform Test-Time Augmentation (TTA) and return predictions.\n    \n    Parameters:\n        - loader: DataLoader containing test images\n        - model: Trained PyTorch model\n        - n_matches: Number of top predictions to return per image\n        - tta_transforms: Number of augmentations per image\n    \n    Returns:\n        - preds: TTA-averaged top predictions (indices)\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n    preds = []\n    \n    with torch.no_grad():\n        for sample in loader:\n            input_images = sample[\"image\"].to(device)\n            tta_outputs = []\n            \n            # Inference on original images (weighted more)\n            original_output = model(input_images)\n            tta_outputs.append(1.5 * torch.sigmoid(original_output).cpu().numpy())\n            \n            # Define a list of augmentation functions\n            transform_list = [\n                lambda x: torch.flip(x, dims=[-1]),  # Horizontal Flip\n                lambda x: T.ColorJitter(brightness=0.1, contrast=0.1)(x),  # Color Jitter\n                lambda x: T.RandomAffine(degrees=5, translate=(0.05, 0.05))(x),  # Affine transform\n                lambda x: T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))(x)  # Gaussian Blur\n            ]\n            \n            for _ in range(tta_transforms):\n                aug_fn = np.random.choice(transform_list)\n                aug_input = aug_fn(input_images)\n                outputs = model(aug_input)\n                tta_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n            \n            # Average predictions and get top classes\n            avg_outputs = np.mean(tta_outputs, axis=0)\n            preds.extend(np.argsort(-avg_outputs, axis=1)[:, :n_matches])\n    \n    return np.array(preds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.393093Z","iopub.execute_input":"2025-03-25T13:50:01.393375Z","iopub.status.idle":"2025-03-25T13:50:01.411402Z","shell.execute_reply.started":"2025-03-25T13:50:01.393353Z","shell.execute_reply":"2025-03-25T13:50:01.410381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DataFrame of test images\ntest_df = pd.DataFrame({\n    \"image_id\": os.listdir(TEST_DATA_FOLDER),\n    \"hotel_id\": \"\"\n}).sort_values(by=\"image_id\")\n\n# Instantiate the dataset and dataloader\ntest_dataset = HotelImageDataset(test_df, transform=base_transform, data_folder=TEST_DATA_FOLDER)\nbatch_size = 64\nnum_workers = 2\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.412525Z","iopub.execute_input":"2025-03-25T13:50:01.412858Z","iopub.status.idle":"2025-03-25T13:50:01.437847Z","shell.execute_reply.started":"2025-03-25T13:50:01.412831Z","shell.execute_reply":"2025-03-25T13:50:01.437007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DataFrame of test images\ntest_df = pd.DataFrame({\n    \"image_id\": os.listdir(TEST_DATA_FOLDER),\n    \"hotel_id\": \"\"\n}).sort_values(by=\"image_id\")\n\n# Instantiate the dataset and dataloader\ntest_dataset = HotelImageDataset(test_df, transform=base_transform, data_folder=TEST_DATA_FOLDER)\nbatch_size = 64\nnum_workers = 2\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T13:50:01.438990Z","iopub.execute_input":"2025-03-25T13:50:01.439293Z","iopub.status.idle":"2025-03-25T13:50:01.459809Z","shell.execute_reply.started":"2025-03-25T13:50:01.439268Z","shell.execute_reply":"2025-03-25T13:50:01.458583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HotelIdModel(nn.Module):\n    def __init__(self, n_classes=100, backbone_name=\"resnet34\"):\n        super(HotelIdModel, self).__init__()\n        \n        self.backbone = timm.create_model(backbone_name, num_classes=n_classes, pretrained=False)\n\n    def forward(self, x):\n        return self.backbone(x)","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.460838Z","iopub.execute_input":"2025-03-25T13:50:01.461192Z","iopub.status.idle":"2025-03-25T13:50:01.471628Z","shell.execute_reply.started":"2025-03-25T13:50:01.461167Z","shell.execute_reply":"2025-03-25T13:50:01.470277Z"},"papermill":{"duration":0.031755,"end_time":"2025-03-19T20:06:14.119186","exception":false,"start_time":"2025-03-19T20:06:14.087431","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model helper functions","metadata":{"id":"YMZYKhUSneMY","papermill":{"duration":0.023092,"end_time":"2025-03-19T20:06:14.164334","exception":false,"start_time":"2025-03-19T20:06:14.141242","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision.transforms as T\n\ndef predict_tta(loader, model, n_matches=5, tta_transforms=3):\n    \"\"\"\n    Perform Test-Time Augmentation (TTA) and return predictions.\n    \n    Parameters:\n        - loader: DataLoader containing test images\n        - model: Trained PyTorch model\n        - n_matches: Number of top predictions to return\n        - tta_transforms: Number of augmentations per image\n    \n    Returns:\n        - preds: TTA-averaged predictions\n    \"\"\"\n    # Automatically detect device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model.to(device)\n    model.eval()\n    preds = []\n\n    with torch.no_grad():\n        for sample in loader:\n            input_images = sample['image'].to(device)\n\n            tta_outputs = []\n            \n            # Original image inference (weighted more)\n            original_output = model(input_images)\n            tta_outputs.append(1.5 * torch.sigmoid(original_output).cpu().numpy())  # Weighting original image\n\n            # Define transformations for TTA\n            transform_list = [\n                lambda x: torch.flip(x, dims=[-1]),  # Horizontal Flip\n                lambda x: T.ColorJitter(brightness=0.1, contrast=0.1)(x),  # Mild brightness/contrast\n                lambda x: T.RandomAffine(degrees=5, translate=(0.05, 0.05))(x),  # Small rotations/translations\n                lambda x: T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))(x)  # Mild blur\n            ]\n            \n            for _ in range(tta_transforms):\n                aug_fn = np.random.choice(transform_list)  # Randomly choose one augmentation\n                aug_input = aug_fn(input_images)\n                outputs = model(aug_input)\n                tta_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n\n            # Average multiple augmented predictions\n            avg_outputs = np.mean(tta_outputs, axis=0)\n            preds.extend(avg_outputs)\n\n    # Get top predictions\n    preds = np.argsort(-np.array(preds), axis=1)[:, :n_matches]\n    return preds\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.472823Z","iopub.execute_input":"2025-03-25T13:50:01.473288Z","iopub.status.idle":"2025-03-25T13:50:01.491821Z","shell.execute_reply.started":"2025-03-25T13:50:01.473247Z","shell.execute_reply":"2025-03-25T13:50:01.490690Z"},"papermill":{"duration":0.054752,"end_time":"2025-03-19T20:06:14.245869","exception":false,"start_time":"2025-03-19T20:06:14.191117","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A\nimport albumentations.pytorch as APT\nimport cv2 \n\n# used for training dataset - augmentations and occlusions\ntrain_transform = A.Compose([\n    A.RandomCrop(width=64, height=64),\n    A.HorizontalFlip(p=0.75),\n    #A.VerticalFlip(p=0.0),\n    A.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=cv2.INTER_NEAREST, border_mode=cv2.BORDER_CONSTANT),\n    A.OpticalDistortion(p=0.25, distort_limit=0.05, shift_limit=0.01),\n    A.Perspective(p=0.25, scale=(0.05, 0.1)),\n    A.ColorJitter(p=0.75, brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n    A.CoarseDropout(p=0.5, min_holes=1, max_holes=5, \n                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//8,\n                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//8), # normal coarse dropout\n    \n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions in test data\n    #A.RandomBrightnessContrast(p=0.75),\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# used for validation dataset - only occlusions\nval_transform = A.Compose([\n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# no augmentations\nbase_transform = A.Compose([\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.492754Z","iopub.execute_input":"2025-03-25T13:50:01.493052Z","iopub.status.idle":"2025-03-25T13:50:01.514308Z","shell.execute_reply.started":"2025-03-25T13:50:01.493029Z","shell.execute_reply":"2025-03-25T13:50:01.513407Z"},"papermill":{"duration":0.036509,"end_time":"2025-03-19T20:06:14.319893","exception":false,"start_time":"2025-03-19T20:06:14.283384","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare data","metadata":{"id":"AwShW1wXniD6","papermill":{"duration":0.022053,"end_time":"2025-03-19T20:06:14.363139","exception":false,"start_time":"2025-03-19T20:06:14.341086","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_df = pd.DataFrame(data={\"image_id\": os.listdir(TEST_DATA_FOLDER), \"hotel_id\": \"\"}).sort_values(by=\"image_id\")","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.515179Z","iopub.execute_input":"2025-03-25T13:50:01.515454Z","iopub.status.idle":"2025-03-25T13:50:01.541036Z","shell.execute_reply.started":"2025-03-25T13:50:01.515430Z","shell.execute_reply":"2025-03-25T13:50:01.539863Z"},"executionInfo":{"elapsed":3742,"status":"ok","timestamp":1619311036476,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"discrete-right","outputId":"c21ed589-3139-4919-b5d5-07bcf6f1df15","papermill":{"duration":0.0436,"end_time":"2025-03-19T20:06:14.429198","exception":false,"start_time":"2025-03-19T20:06:14.385598","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# code hotel_id mapping created in training notebook by encoding hotel_ids\nhotel_id_code_df = pd.read_csv('../input/resnet-training/hotel_id_code_mapping.csv')\nhotel_id_code_map = hotel_id_code_df.set_index('hotel_id_code').to_dict()[\"hotel_id\"]","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.542092Z","iopub.execute_input":"2025-03-25T13:50:01.542379Z","iopub.status.idle":"2025-03-25T13:50:01.568087Z","shell.execute_reply.started":"2025-03-25T13:50:01.542354Z","shell.execute_reply":"2025-03-25T13:50:01.566992Z"},"papermill":{"duration":0.046428,"end_time":"2025-03-19T20:06:14.496582","exception":false,"start_time":"2025-03-19T20:06:14.450154","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare model","metadata":{"id":"5JPdD2bpnniP","papermill":{"duration":0.020706,"end_time":"2025-03-19T20:06:14.538145","exception":false,"start_time":"2025-03-19T20:06:14.517439","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_model(model_type, backbone_name, checkpoint_path, args):\n    model = HotelIdModel(args.n_classes, backbone_name)\n        \n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint[\"model\"])\n    model = model.to(args.device)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.569141Z","iopub.execute_input":"2025-03-25T13:50:01.569508Z","iopub.status.idle":"2025-03-25T13:50:01.575430Z","shell.execute_reply.started":"2025-03-25T13:50:01.569472Z","shell.execute_reply":"2025-03-25T13:50:01.574280Z"},"papermill":{"duration":0.031841,"end_time":"2025-03-19T20:06:14.592834","exception":false,"start_time":"2025-03-19T20:06:14.560993","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class args:\n    batch_size = 64\n    num_workers = 2\n    n_classes = hotel_id_code_df[\"hotel_id\"].nunique()\n    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    \nseed_everything(seed=SEED)\n\ntest_dataset = HotelImageDataset(test_df, base_transform, data_folder=TEST_DATA_FOLDER)\ntest_loader = DataLoader(test_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.576446Z","iopub.execute_input":"2025-03-25T13:50:01.576759Z","iopub.status.idle":"2025-03-25T13:50:01.605070Z","shell.execute_reply.started":"2025-03-25T13:50:01.576734Z","shell.execute_reply":"2025-03-25T13:50:01.603993Z"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1619311064188,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"appointed-machinery","papermill":{"duration":0.036933,"end_time":"2025-03-19T20:06:14.651348","exception":false,"start_time":"2025-03-19T20:06:14.614415","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndef get_model(model_type, backbone_name, checkpoint_path, args):\n    model = HotelIdModel(args.n_classes, backbone_name)\n    \n    # Load the checkpoint with map_location\n    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  \n    \n    model.load_state_dict(checkpoint[\"model\"])\n    model = model.to(args.device)  # Ensure it's moved to the correct device (CPU/GPU)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.606350Z","iopub.execute_input":"2025-03-25T13:50:01.606720Z","iopub.status.idle":"2025-03-25T13:50:01.621217Z","shell.execute_reply.started":"2025-03-25T13:50:01.606685Z","shell.execute_reply":"2025-03-25T13:50:01.620168Z"},"papermill":{"duration":0.031549,"end_time":"2025-03-19T20:06:14.705499","exception":false,"start_time":"2025-03-19T20:06:14.673950","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_model(\"classification\", \"resnet34\", \n                  \"../input/resnet-training/checkpoint-classification-model-resnet34-256x256.pt\", \n                  args)\n\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:01.624623Z","iopub.execute_input":"2025-03-25T13:50:01.624984Z","iopub.status.idle":"2025-03-25T13:50:02.404937Z","shell.execute_reply.started":"2025-03-25T13:50:01.624955Z","shell.execute_reply":"2025-03-25T13:50:02.403570Z"},"papermill":{"duration":3.997955,"end_time":"2025-03-19T20:06:18.725110","exception":false,"start_time":"2025-03-19T20:06:14.727155","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.021888,"end_time":"2025-03-19T20:06:18.769397","exception":false,"start_time":"2025-03-19T20:06:18.747509","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\npreds = predict_tta(test_loader, model, n_matches=5, tta_transforms=3)\n# replace classes with hotel_id using mapping created in trainig notebook\npreds = [[hotel_id_code_map[b] for b in a] for a in preds]\n# transform array of hotel_ids into string\ntest_df[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\") for l in preds]\n\ntest_df.to_csv(\"submission.csv\", index=False)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-25T13:50:02.406047Z","iopub.execute_input":"2025-03-25T13:50:02.406312Z","iopub.status.idle":"2025-03-25T13:50:03.029424Z","shell.execute_reply.started":"2025-03-25T13:50:02.406289Z","shell.execute_reply":"2025-03-25T13:50:03.028254Z"},"papermill":{"duration":0.843678,"end_time":"2025-03-19T20:06:19.634726","exception":false,"start_time":"2025-03-19T20:06:18.791048","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}