{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea9432d",
   "metadata": {
    "id": "DAY5rHgTm7e8",
    "papermill": {
     "duration": 0.022235,
     "end_time": "2025-03-19T20:05:59.145418",
     "exception": false,
     "start_time": "2025-03-19T20:05:59.123183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intro\n",
    "Inference notebook for [Hotel-ID starter - classification - traning](https://www.kaggle.com/code/michaln/hotel-id-starter-classification-traning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d692e75",
   "metadata": {
    "papermill": {
     "duration": 0.020644,
     "end_time": "2025-03-19T20:05:59.188756",
     "exception": false,
     "start_time": "2025-03-19T20:05:59.168112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd5e852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:05:59.235537Z",
     "iopub.status.busy": "2025-03-19T20:05:59.235051Z",
     "iopub.status.idle": "2025-03-19T20:06:10.724401Z",
     "shell.execute_reply": "2025-03-19T20:06:10.723070Z"
    },
    "executionInfo": {
     "elapsed": 16271,
     "status": "ok",
     "timestamp": 1619310548121,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "alleged-legislation",
    "outputId": "c6541e5f-ffb4-4609-d6c6-39784e6a07b1",
    "papermill": {
     "duration": 11.516733,
     "end_time": "2025-03-19T20:06:10.727259",
     "exception": false,
     "start_time": "2025-03-19T20:05:59.210526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc953eaa",
   "metadata": {
    "id": "cZoSOL9Qm-Yr",
    "papermill": {
     "duration": 0.020585,
     "end_time": "2025-03-19T20:06:10.768628",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.748043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ca11ad",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:10.815166Z",
     "iopub.status.busy": "2025-03-19T20:06:10.814842Z",
     "iopub.status.idle": "2025-03-19T20:06:10.819841Z",
     "shell.execute_reply": "2025-03-19T20:06:10.818890Z"
    },
    "executionInfo": {
     "elapsed": 14459,
     "status": "ok",
     "timestamp": 1619310548121,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "expired-matter",
    "papermill": {
     "duration": 0.031884,
     "end_time": "2025-03-19T20:06:10.821888",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.790004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdcfe864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:10.864881Z",
     "iopub.status.busy": "2025-03-19T20:06:10.864539Z",
     "iopub.status.idle": "2025-03-19T20:06:10.869190Z",
     "shell.execute_reply": "2025-03-19T20:06:10.868138Z"
    },
    "executionInfo": {
     "elapsed": 16003,
     "status": "ok",
     "timestamp": 1619310550014,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "extreme-problem",
    "papermill": {
     "duration": 0.028491,
     "end_time": "2025-03-19T20:06:10.871353",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.842862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df1c407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:10.914505Z",
     "iopub.status.busy": "2025-03-19T20:06:10.914235Z",
     "iopub.status.idle": "2025-03-19T20:06:10.919095Z",
     "shell.execute_reply": "2025-03-19T20:06:10.917960Z"
    },
    "executionInfo": {
     "elapsed": 19672,
     "status": "ok",
     "timestamp": 1619310554099,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "angry-domain",
    "papermill": {
     "duration": 0.0289,
     "end_time": "2025-03-19T20:06:10.921250",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.892350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b92ff",
   "metadata": {
    "id": "0B00pe7mnBTj",
    "papermill": {
     "duration": 0.020614,
     "end_time": "2025-03-19T20:06:10.962719",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.942105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c1f698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:11.006734Z",
     "iopub.status.busy": "2025-03-19T20:06:11.006050Z",
     "iopub.status.idle": "2025-03-19T20:06:11.010973Z",
     "shell.execute_reply": "2025-03-19T20:06:11.009913Z"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1619310979015,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "contained-brief",
    "papermill": {
     "duration": 0.029907,
     "end_time": "2025-03-19T20:06:11.013236",
     "exception": false,
     "start_time": "2025-03-19T20:06:10.983329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "\n",
    "PROJECT_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\"\n",
    "TEST_DATA_FOLDER = PROJECT_FOLDER + \"test_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642a3969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:11.057066Z",
     "iopub.status.busy": "2025-03-19T20:06:11.056008Z",
     "iopub.status.idle": "2025-03-19T20:06:11.062671Z",
     "shell.execute_reply": "2025-03-19T20:06:11.061646Z"
    },
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1619310979515,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "PZvmFng7ctO3",
    "outputId": "dce0cc91-8e70-4acc-a0b8-6763ffffd5ca",
    "papermill": {
     "duration": 0.030579,
     "end_time": "2025-03-19T20:06:11.064812",
     "exception": false,
     "start_time": "2025-03-19T20:06:11.034233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train_images', 'train_masks', 'test_images']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(PROJECT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d0963e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:11.112330Z",
     "iopub.status.busy": "2025-03-19T20:06:11.112035Z",
     "iopub.status.idle": "2025-03-19T20:06:11.117942Z",
     "shell.execute_reply": "2025-03-19T20:06:11.116782Z"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1619310981653,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "eastern-content",
    "papermill": {
     "duration": 0.033715,
     "end_time": "2025-03-19T20:06:11.120143",
     "exception": false,
     "start_time": "2025-03-19T20:06:11.086428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f27dd",
   "metadata": {
    "id": "xaJKvvuKnW4k",
    "papermill": {
     "duration": 0.021835,
     "end_time": "2025-03-19T20:06:11.165014",
     "exception": false,
     "start_time": "2025-03-19T20:06:11.143179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d726b765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:11.210786Z",
     "iopub.status.busy": "2025-03-19T20:06:11.210461Z",
     "iopub.status.idle": "2025-03-19T20:06:13.905638Z",
     "shell.execute_reply": "2025-03-19T20:06:13.904825Z"
    },
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1619310984075,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "revolutionary-membership",
    "papermill": {
     "duration": 2.720081,
     "end_time": "2025-03-19T20:06:13.908275",
     "exception": false,
     "start_time": "2025-03-19T20:06:11.188194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "import cv2 \n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# used for training dataset - augmentations and occlusions\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.75),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.ShiftScaleRotate(p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.OpticalDistortion(p=0.25),\n",
    "    A.Perspective(p=0.25),\n",
    "    A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n",
    "                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n",
    "                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//4), # normal coarse dropout\n",
    "    \n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions in test data\n",
    "\n",
    "    A.RandomBrightnessContrast(p=0.75),\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# used for validation dataset - only occlusions\n",
    "val_transform = A.Compose([\n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a372ac2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:13.952248Z",
     "iopub.status.busy": "2025-03-19T20:06:13.951871Z",
     "iopub.status.idle": "2025-03-19T20:06:13.959075Z",
     "shell.execute_reply": "2025-03-19T20:06:13.958176Z"
    },
    "papermill": {
     "duration": 0.031709,
     "end_time": "2025-03-19T20:06:13.961286",
     "exception": false,
     "start_time": "2025-03-19T20:06:13.929577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_image(img):\n",
    "    w, h, c = np.shape(img)\n",
    "    if w > h:\n",
    "        pad = int((w - h) / 2)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n",
    "    else:\n",
    "        pad = int((h - w) / 2)\n",
    "        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def open_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = pad_image(img)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16422347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.007639Z",
     "iopub.status.busy": "2025-03-19T20:06:14.007162Z",
     "iopub.status.idle": "2025-03-19T20:06:14.018661Z",
     "shell.execute_reply": "2025-03-19T20:06:14.017360Z"
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1619310984077,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "found-mouth",
    "papermill": {
     "duration": 0.040625,
     "end_time": "2025-03-19T20:06:14.022795",
     "exception": false,
     "start_time": "2025-03-19T20:06:13.982170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HotelImageDataset:\n",
    "    def __init__(self, data, transform=None, data_folder=\"train_images/\"):\n",
    "        self.data = data\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data.iloc[idx]\n",
    "        image_path = self.data_folder + record[\"image_id\"]\n",
    "        \n",
    "        image = np.array(open_and_preprocess_image(image_path)).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        \n",
    "        return {\n",
    "            \"image\" : image,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e27cdf",
   "metadata": {
    "id": "NMDM4PwPnced",
    "papermill": {
     "duration": 0.02149,
     "end_time": "2025-03-19T20:06:14.066209",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.044719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82813c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.111613Z",
     "iopub.status.busy": "2025-03-19T20:06:14.111294Z",
     "iopub.status.idle": "2025-03-19T20:06:14.117109Z",
     "shell.execute_reply": "2025-03-19T20:06:14.116160Z"
    },
    "papermill": {
     "duration": 0.031755,
     "end_time": "2025-03-19T20:06:14.119186",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.087431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HotelIdModel(nn.Module):\n",
    "    def __init__(self, n_classes=100, backbone_name=\"resnet34\"):\n",
    "        super(HotelIdModel, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(backbone_name, num_classes=n_classes, pretrained=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ec336",
   "metadata": {
    "id": "YMZYKhUSneMY",
    "papermill": {
     "duration": 0.023092,
     "end_time": "2025-03-19T20:06:14.164334",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.141242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717d0689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.226119Z",
     "iopub.status.busy": "2025-03-19T20:06:14.225802Z",
     "iopub.status.idle": "2025-03-19T20:06:14.242946Z",
     "shell.execute_reply": "2025-03-19T20:06:14.241904Z"
    },
    "papermill": {
     "duration": 0.054752,
     "end_time": "2025-03-19T20:06:14.245869",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.191117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def predict_tta(loader, model, n_matches=5, tta_transforms=3):\n",
    "    \"\"\"\n",
    "    Perform Test-Time Augmentation (TTA) and return predictions.\n",
    "    \n",
    "    Parameters:\n",
    "        - loader: DataLoader containing test images\n",
    "        - model: Trained PyTorch model\n",
    "        - n_matches: Number of top predictions to return\n",
    "        - tta_transforms: Number of augmentations per image\n",
    "    \n",
    "    Returns:\n",
    "        - preds: TTA-averaged predictions\n",
    "    \"\"\"\n",
    "    # Automatically detect device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in loader:\n",
    "            input_images = sample['image'].to(device)\n",
    "\n",
    "            tta_outputs = []\n",
    "            \n",
    "            # Original image inference (weighted more)\n",
    "            original_output = model(input_images)\n",
    "            tta_outputs.append(1.5 * torch.sigmoid(original_output).cpu().numpy())  # Weighting original image\n",
    "\n",
    "            # Define transformations for TTA\n",
    "            transform_list = [\n",
    "                lambda x: torch.flip(x, dims=[-1]),  # Horizontal Flip\n",
    "                lambda x: T.ColorJitter(brightness=0.1, contrast=0.1)(x),  # Mild brightness/contrast\n",
    "                lambda x: T.RandomAffine(degrees=5, translate=(0.05, 0.05))(x),  # Small rotations/translations\n",
    "                lambda x: T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))(x)  # Mild blur\n",
    "            ]\n",
    "            \n",
    "            for _ in range(tta_transforms):\n",
    "                aug_fn = np.random.choice(transform_list)  # Randomly choose one augmentation\n",
    "                aug_input = aug_fn(input_images)\n",
    "                outputs = model(aug_input)\n",
    "                tta_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "            # Average multiple augmented predictions\n",
    "            avg_outputs = np.mean(tta_outputs, axis=0)\n",
    "            preds.extend(avg_outputs)\n",
    "\n",
    "    # Get top predictions\n",
    "    preds = np.argsort(-np.array(preds), axis=1)[:, :n_matches]\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750d302f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.306444Z",
     "iopub.status.busy": "2025-03-19T20:06:14.306101Z",
     "iopub.status.idle": "2025-03-19T20:06:14.317521Z",
     "shell.execute_reply": "2025-03-19T20:06:14.316484Z"
    },
    "papermill": {
     "duration": 0.036509,
     "end_time": "2025-03-19T20:06:14.319893",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.283384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "import cv2 \n",
    "\n",
    "# used for training dataset - augmentations and occlusions\n",
    "train_transform = A.Compose([\n",
    "    A.RandomCrop(width=64, height=64),\n",
    "    A.HorizontalFlip(p=0.75),\n",
    "    #A.VerticalFlip(p=0.0),\n",
    "    A.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=cv2.INTER_NEAREST, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.OpticalDistortion(p=0.25, distort_limit=0.05, shift_limit=0.01),\n",
    "    A.Perspective(p=0.25, scale=(0.05, 0.1)),\n",
    "    A.ColorJitter(p=0.75, brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "    A.CoarseDropout(p=0.5, min_holes=1, max_holes=5, \n",
    "                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//8,\n",
    "                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//8), # normal coarse dropout\n",
    "    \n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions in test data\n",
    "    #A.RandomBrightnessContrast(p=0.75),\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# used for validation dataset - only occlusions\n",
    "val_transform = A.Compose([\n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# no augmentations\n",
    "base_transform = A.Compose([\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9470c6e8",
   "metadata": {
    "id": "AwShW1wXniD6",
    "papermill": {
     "duration": 0.022053,
     "end_time": "2025-03-19T20:06:14.363139",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.341086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246edda9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.408495Z",
     "iopub.status.busy": "2025-03-19T20:06:14.408175Z",
     "iopub.status.idle": "2025-03-19T20:06:14.426752Z",
     "shell.execute_reply": "2025-03-19T20:06:14.425647Z"
    },
    "executionInfo": {
     "elapsed": 3742,
     "status": "ok",
     "timestamp": 1619311036476,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "discrete-right",
    "outputId": "c21ed589-3139-4919-b5d5-07bcf6f1df15",
    "papermill": {
     "duration": 0.0436,
     "end_time": "2025-03-19T20:06:14.429198",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.385598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data={\"image_id\": os.listdir(TEST_DATA_FOLDER), \"hotel_id\": \"\"}).sort_values(by=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "025cc513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.473943Z",
     "iopub.status.busy": "2025-03-19T20:06:14.473629Z",
     "iopub.status.idle": "2025-03-19T20:06:14.493636Z",
     "shell.execute_reply": "2025-03-19T20:06:14.492185Z"
    },
    "papermill": {
     "duration": 0.046428,
     "end_time": "2025-03-19T20:06:14.496582",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.450154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code hotel_id mapping created in training notebook by encoding hotel_ids\n",
    "hotel_id_code_df = pd.read_csv('../input/resnet-training/hotel_id_code_mapping.csv')\n",
    "hotel_id_code_map = hotel_id_code_df.set_index('hotel_id_code').to_dict()[\"hotel_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dcb18",
   "metadata": {
    "id": "5JPdD2bpnniP",
    "papermill": {
     "duration": 0.020706,
     "end_time": "2025-03-19T20:06:14.538145",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.517439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a820944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.584987Z",
     "iopub.status.busy": "2025-03-19T20:06:14.584659Z",
     "iopub.status.idle": "2025-03-19T20:06:14.590427Z",
     "shell.execute_reply": "2025-03-19T20:06:14.589422Z"
    },
    "papermill": {
     "duration": 0.031841,
     "end_time": "2025-03-19T20:06:14.592834",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.560993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(model_type, backbone_name, checkpoint_path, args):\n",
    "    model = HotelIdModel(args.n_classes, backbone_name)\n",
    "        \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be345074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.636675Z",
     "iopub.status.busy": "2025-03-19T20:06:14.636340Z",
     "iopub.status.idle": "2025-03-19T20:06:14.648764Z",
     "shell.execute_reply": "2025-03-19T20:06:14.647649Z"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1619311064188,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "appointed-machinery",
    "papermill": {
     "duration": 0.036933,
     "end_time": "2025-03-19T20:06:14.651348",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.614415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    batch_size = 64\n",
    "    num_workers = 2\n",
    "    n_classes = hotel_id_code_df[\"hotel_id\"].nunique()\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    \n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "test_dataset = HotelImageDataset(test_df, base_transform, data_folder=TEST_DATA_FOLDER)\n",
    "test_loader = DataLoader(test_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2b9fa6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.697115Z",
     "iopub.status.busy": "2025-03-19T20:06:14.696812Z",
     "iopub.status.idle": "2025-03-19T20:06:14.702992Z",
     "shell.execute_reply": "2025-03-19T20:06:14.701870Z"
    },
    "papermill": {
     "duration": 0.031549,
     "end_time": "2025-03-19T20:06:14.705499",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.673950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_model(model_type, backbone_name, checkpoint_path, args):\n",
    "    model = HotelIdModel(args.n_classes, backbone_name)\n",
    "    \n",
    "    # Load the checkpoint with map_location\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  \n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model = model.to(args.device)  # Ensure it's moved to the correct device (CPU/GPU)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc5a45ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:14.751609Z",
     "iopub.status.busy": "2025-03-19T20:06:14.751320Z",
     "iopub.status.idle": "2025-03-19T20:06:18.721609Z",
     "shell.execute_reply": "2025-03-19T20:06:18.720630Z"
    },
    "papermill": {
     "duration": 3.997955,
     "end_time": "2025-03-19T20:06:18.725110",
     "exception": false,
     "start_time": "2025-03-19T20:06:14.727155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotelIdModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=512, out_features=3116, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = get_model(\"classification\", \"resnet34\", \n",
    "                  \"../input/resnet-training/checkpoint-classification-model-resnet34-256x256.pt\", \n",
    "                  args)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ccd27f",
   "metadata": {
    "papermill": {
     "duration": 0.021888,
     "end_time": "2025-03-19T20:06:18.769397",
     "exception": false,
     "start_time": "2025-03-19T20:06:18.747509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a51c677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T20:06:18.815311Z",
     "iopub.status.busy": "2025-03-19T20:06:18.814962Z",
     "iopub.status.idle": "2025-03-19T20:06:19.631813Z",
     "shell.execute_reply": "2025-03-19T20:06:19.630430Z"
    },
    "papermill": {
     "duration": 0.843678,
     "end_time": "2025-03-19T20:06:19.634726",
     "exception": false,
     "start_time": "2025-03-19T20:06:18.791048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 107 ms, total: 1.15 s\n",
      "Wall time: 795 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc.jpg</td>\n",
       "      <td>24700 18800 308350 108817 40941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id                         hotel_id\n",
       "0  abc.jpg  24700 18800 308350 108817 40941"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = predict_tta(test_loader, model, n_matches=5, tta_transforms=3)\n",
    "# replace classes with hotel_id using mapping created in trainig notebook\n",
    "preds = [[hotel_id_code_map[b] for b in a] for a in preds]\n",
    "# transform array of hotel_ids into string\n",
    "test_df[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\") for l in preds]\n",
    "\n",
    "test_df.to_csv(\"submission.csv\", index=False)\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4957097,
     "sourceId": 35150,
     "sourceType": "competition"
    },
    {
     "datasetId": 1027206,
     "sourceId": 3951115,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 96549317,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30191,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33.821406,
   "end_time": "2025-03-19T20:06:22.564645",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T20:05:48.743239",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
