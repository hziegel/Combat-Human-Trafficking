{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3276c01",
   "metadata": {
    "id": "DAY5rHgTm7e8",
    "papermill": {
     "duration": 0.01766,
     "end_time": "2025-02-28T18:03:29.442099",
     "exception": false,
     "start_time": "2025-02-28T18:03:29.424439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intro\n",
    "Inference notebook for [Hotel-ID starter - classification - traning](https://www.kaggle.com/code/michaln/hotel-id-starter-classification-traning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d85d5d",
   "metadata": {
    "papermill": {
     "duration": 0.016503,
     "end_time": "2025-02-28T18:03:29.474535",
     "exception": false,
     "start_time": "2025-02-28T18:03:29.458032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbcdfc5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:10.556070Z",
     "iopub.status.busy": "2025-04-24T15:56:10.555650Z",
     "iopub.status.idle": "2025-04-24T15:56:25.409831Z",
     "shell.execute_reply": "2025-04-24T15:56:25.409000Z",
     "shell.execute_reply.started": "2025-04-24T15:56:10.556036Z"
    },
    "executionInfo": {
     "elapsed": 16271,
     "status": "ok",
     "timestamp": 1619310548121,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "alleged-legislation",
    "outputId": "c6541e5f-ffb4-4609-d6c6-39784e6a07b1",
    "papermill": {
     "duration": 9.265524,
     "end_time": "2025-02-28T18:03:38.760161",
     "exception": false,
     "start_time": "2025-02-28T18:03:29.494637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2700d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca7a66",
   "metadata": {
    "id": "cZoSOL9Qm-Yr",
    "papermill": {
     "duration": 0.015743,
     "end_time": "2025-02-28T18:03:38.791631",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.775888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066887a5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.411000Z",
     "iopub.status.busy": "2025-04-24T15:56:25.410722Z",
     "iopub.status.idle": "2025-04-24T15:56:25.755269Z",
     "shell.execute_reply": "2025-04-24T15:56:25.754439Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.410971Z"
    },
    "executionInfo": {
     "elapsed": 14459,
     "status": "ok",
     "timestamp": 1619310548121,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "expired-matter",
    "papermill": {
     "duration": 0.023666,
     "end_time": "2025-02-28T18:03:38.831285",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.807619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e466de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.757495Z",
     "iopub.status.busy": "2025-04-24T15:56:25.757019Z",
     "iopub.status.idle": "2025-04-24T15:56:25.762831Z",
     "shell.execute_reply": "2025-04-24T15:56:25.761586Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.757470Z"
    },
    "executionInfo": {
     "elapsed": 16003,
     "status": "ok",
     "timestamp": 1619310550014,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "extreme-problem",
    "papermill": {
     "duration": 0.020415,
     "end_time": "2025-02-28T18:03:38.867171",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.846756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image as pil_image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59525f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.764000Z",
     "iopub.status.busy": "2025-04-24T15:56:25.763723Z",
     "iopub.status.idle": "2025-04-24T15:56:25.786125Z",
     "shell.execute_reply": "2025-04-24T15:56:25.785190Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.763976Z"
    },
    "executionInfo": {
     "elapsed": 19672,
     "status": "ok",
     "timestamp": 1619310554099,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "angry-domain",
    "papermill": {
     "duration": 0.02016,
     "end_time": "2025-02-28T18:03:38.902711",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.882551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc8a04",
   "metadata": {
    "id": "0B00pe7mnBTj",
    "papermill": {
     "duration": 0.016011,
     "end_time": "2025-02-28T18:03:38.934404",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.918393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b3b030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.787316Z",
     "iopub.status.busy": "2025-04-24T15:56:25.787054Z",
     "iopub.status.idle": "2025-04-24T15:56:25.805656Z",
     "shell.execute_reply": "2025-04-24T15:56:25.804619Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.787294Z"
    },
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1619310979015,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "contained-brief",
    "papermill": {
     "duration": 0.021827,
     "end_time": "2025-02-28T18:03:38.971649",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.949822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "IMG_SIZE = 256\n",
    "\n",
    "PROJECT_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\"\n",
    "TEST_DATA_FOLDER = PROJECT_FOLDER + \"test_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81857006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.807093Z",
     "iopub.status.busy": "2025-04-24T15:56:25.806625Z",
     "iopub.status.idle": "2025-04-24T15:56:25.831089Z",
     "shell.execute_reply": "2025-04-24T15:56:25.830255Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.807067Z"
    },
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1619310979515,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "PZvmFng7ctO3",
    "outputId": "dce0cc91-8e70-4acc-a0b8-6763ffffd5ca",
    "papermill": {
     "duration": 0.024052,
     "end_time": "2025-02-28T18:03:39.011278",
     "exception": false,
     "start_time": "2025-02-28T18:03:38.987226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train_images', 'train_masks', 'test_images']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(PROJECT_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825553d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.832375Z",
     "iopub.status.busy": "2025-04-24T15:56:25.832017Z",
     "iopub.status.idle": "2025-04-24T15:56:25.847975Z",
     "shell.execute_reply": "2025-04-24T15:56:25.847014Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.832352Z"
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1619310981653,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "eastern-content",
    "papermill": {
     "duration": 0.023645,
     "end_time": "2025-02-28T18:03:39.051762",
     "exception": false,
     "start_time": "2025-02-28T18:03:39.028117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b59136",
   "metadata": {
    "id": "xaJKvvuKnW4k",
    "papermill": {
     "duration": 0.015254,
     "end_time": "2025-02-28T18:03:39.082756",
     "exception": false,
     "start_time": "2025-02-28T18:03:39.067502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bd6a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:25.849261Z",
     "iopub.status.busy": "2025-04-24T15:56:25.848945Z",
     "iopub.status.idle": "2025-04-24T15:56:59.285080Z",
     "shell.execute_reply": "2025-04-24T15:56:59.284150Z",
     "shell.execute_reply.started": "2025-04-24T15:56:25.849231Z"
    },
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1619310984075,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "revolutionary-membership",
    "papermill": {
     "duration": 2.034041,
     "end_time": "2025-02-28T18:03:41.132992",
     "exception": false,
     "start_time": "2025-02-28T18:03:39.098951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:107: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_31/3729967500.py:14: UserWarning: Argument(s) 'min_holes, max_holes, min_height, max_height, min_width, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.5, min_holes=1, max_holes=6,\n",
      "/tmp/ipykernel_31/3729967500.py:18: UserWarning: Argument(s) 'max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.75, max_holes=1,\n",
      "/tmp/ipykernel_31/3729967500.py:30: UserWarning: Argument(s) 'max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.75, max_holes=1,\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "import cv2 \n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# used for training dataset - augmentations and occlusions\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.75),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.ShiftScaleRotate(p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.OpticalDistortion(p=0.25),\n",
    "    A.Perspective(p=0.25),\n",
    "    A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n",
    "                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n",
    "                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//4), # normal coarse dropout\n",
    "    \n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions in test data\n",
    "\n",
    "    A.RandomBrightnessContrast(p=0.75),\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# used for validation dataset - only occlusions\n",
    "val_transform = A.Compose([\n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce6eb43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.288052Z",
     "iopub.status.busy": "2025-04-24T15:56:59.287596Z",
     "iopub.status.idle": "2025-04-24T15:56:59.294674Z",
     "shell.execute_reply": "2025-04-24T15:56:59.293614Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.288029Z"
    },
    "papermill": {
     "duration": 0.024431,
     "end_time": "2025-02-28T18:03:41.173160",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.148729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_image(img):\n",
    "    w, h, c = np.shape(img)\n",
    "    if w > h:\n",
    "        pad = int((w - h) / 2)\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n",
    "    else:\n",
    "        pad = int((h - w) / 2)\n",
    "        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def open_and_preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = pad_image(img)\n",
    "    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ea4d4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.296206Z",
     "iopub.status.busy": "2025-04-24T15:56:59.295853Z",
     "iopub.status.idle": "2025-04-24T15:56:59.355902Z",
     "shell.execute_reply": "2025-04-24T15:56:59.354998Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.296182Z"
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1619310984077,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "found-mouth",
    "papermill": {
     "duration": 0.023675,
     "end_time": "2025-02-28T18:03:41.213001",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.189326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HotelImageDataset:\n",
    "    def __init__(self, data, transform=None, data_folder=\"train_images/\"):\n",
    "        self.data = data\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data.iloc[idx]\n",
    "        image_path = self.data_folder + record[\"image_id\"]\n",
    "        \n",
    "        image = np.array(open_and_preprocess_image(image_path)).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        \n",
    "        return {\n",
    "            \"image\" : image,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72dc9a",
   "metadata": {
    "id": "NMDM4PwPnced",
    "papermill": {
     "duration": 0.015865,
     "end_time": "2025-02-28T18:03:41.244436",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.228571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37157a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.357008Z",
     "iopub.status.busy": "2025-04-24T15:56:59.356728Z",
     "iopub.status.idle": "2025-04-24T15:56:59.379404Z",
     "shell.execute_reply": "2025-04-24T15:56:59.378220Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.356981Z"
    },
    "papermill": {
     "duration": 0.023735,
     "end_time": "2025-02-28T18:03:41.284093",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.260358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HotelIdModel(nn.Module):\n",
    "    def __init__(self, n_classes=100, backbone_name=\"resnet34\"):\n",
    "        super(HotelIdModel, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(backbone_name, num_classes=n_classes, pretrained=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ed077",
   "metadata": {
    "id": "YMZYKhUSneMY",
    "papermill": {
     "duration": 0.016127,
     "end_time": "2025-02-28T18:03:41.316093",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.299966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54aa399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.380795Z",
     "iopub.status.busy": "2025-04-24T15:56:59.380524Z",
     "iopub.status.idle": "2025-04-24T15:56:59.398351Z",
     "shell.execute_reply": "2025-04-24T15:56:59.397334Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.380767Z"
    },
    "papermill": {
     "duration": 0.023397,
     "end_time": "2025-02-28T18:03:41.354973",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.331576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_tta(loader, model, n_matches=5, tta_transforms=3):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(loader):\n",
    "            input_images = sample['image'].to(args.device)\n",
    "\n",
    "            tta_outputs = []\n",
    "            for _ in range(tta_transforms):\n",
    "                aug_input = torch.flip(input_images, dims=[-1])  # Apply horizontal flip\n",
    "                outputs = model(aug_input)\n",
    "                tta_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "            avg_outputs = np.mean(tta_outputs, axis=0)\n",
    "            preds.extend(avg_outputs)\n",
    "\n",
    "    preds = np.argsort(-np.array(preds), axis=1)[:, :n_matches]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5baec4bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.399852Z",
     "iopub.status.busy": "2025-04-24T15:56:59.399534Z",
     "iopub.status.idle": "2025-04-24T15:56:59.427265Z",
     "shell.execute_reply": "2025-04-24T15:56:59.426166Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.399802Z"
    },
    "papermill": {
     "duration": 0.025921,
     "end_time": "2025-02-28T18:03:41.396764",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.370843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/3377238334.py:11: UserWarning: Argument(s) 'shift_limit' are not valid for transform OpticalDistortion\n",
      "  A.OpticalDistortion(p=0.25, distort_limit=0.05, shift_limit=0.01),\n",
      "/tmp/ipykernel_31/3377238334.py:14: UserWarning: Argument(s) 'min_holes, max_holes, min_height, max_height, min_width, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.5, min_holes=1, max_holes=5,\n",
      "/tmp/ipykernel_31/3377238334.py:18: UserWarning: Argument(s) 'max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.75, max_holes=1,\n",
      "/tmp/ipykernel_31/3377238334.py:29: UserWarning: Argument(s) 'max_holes, min_height, max_height, min_width, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.75, max_holes=1,\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "import cv2 \n",
    "\n",
    "# used for training dataset - augmentations and occlusions\n",
    "train_transform = A.Compose([\n",
    "    A.RandomCrop(width=64, height=64),\n",
    "    A.HorizontalFlip(p=0.75),\n",
    "    #A.VerticalFlip(p=0.0),\n",
    "    A.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=cv2.INTER_NEAREST, border_mode=cv2.BORDER_CONSTANT),\n",
    "    A.OpticalDistortion(p=0.25, distort_limit=0.05, shift_limit=0.01),\n",
    "    A.Perspective(p=0.25, scale=(0.05, 0.1)),\n",
    "    A.ColorJitter(p=0.75, brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
    "    A.CoarseDropout(p=0.5, min_holes=1, max_holes=5, \n",
    "                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//8,\n",
    "                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//8), # normal coarse dropout\n",
    "    \n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions in test data\n",
    "    #A.RandomBrightnessContrast(p=0.75),\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# used for validation dataset - only occlusions\n",
    "val_transform = A.Compose([\n",
    "    A.CoarseDropout(p=0.75, max_holes=1, \n",
    "                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n",
    "                    fill_value=(255,0,0)),# simulating occlusions\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])\n",
    "\n",
    "# no augmentations\n",
    "base_transform = A.Compose([\n",
    "    A.ToFloat(),\n",
    "    APT.transforms.ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea13b9",
   "metadata": {
    "id": "AwShW1wXniD6",
    "papermill": {
     "duration": 0.016038,
     "end_time": "2025-02-28T18:03:41.428918",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.412880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af2fd741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.428589Z",
     "iopub.status.busy": "2025-04-24T15:56:59.428237Z",
     "iopub.status.idle": "2025-04-24T15:56:59.456334Z",
     "shell.execute_reply": "2025-04-24T15:56:59.455432Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.428567Z"
    },
    "executionInfo": {
     "elapsed": 3742,
     "status": "ok",
     "timestamp": 1619311036476,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "discrete-right",
    "outputId": "c21ed589-3139-4919-b5d5-07bcf6f1df15",
    "papermill": {
     "duration": 0.038623,
     "end_time": "2025-02-28T18:03:41.483698",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.445075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(data={\"image_id\": os.listdir(TEST_DATA_FOLDER), \"hotel_id\": \"\"}).sort_values(by=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c86ceab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.457547Z",
     "iopub.status.busy": "2025-04-24T15:56:59.457237Z",
     "iopub.status.idle": "2025-04-24T15:56:59.479896Z",
     "shell.execute_reply": "2025-04-24T15:56:59.478900Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.457520Z"
    },
    "papermill": {
     "duration": 0.033476,
     "end_time": "2025-02-28T18:03:41.533074",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.499598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code hotel_id mapping created in training notebook by encoding hotel_ids\n",
    "hotel_id_code_df = pd.read_csv('../input/resnet-training/hotel_id_code_mapping.csv')\n",
    "hotel_id_code_map = hotel_id_code_df.set_index('hotel_id_code').to_dict()[\"hotel_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c44aae",
   "metadata": {
    "id": "5JPdD2bpnniP",
    "papermill": {
     "duration": 0.01527,
     "end_time": "2025-02-28T18:03:41.564944",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.549674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4307768b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.481149Z",
     "iopub.status.busy": "2025-04-24T15:56:59.480834Z",
     "iopub.status.idle": "2025-04-24T15:56:59.486453Z",
     "shell.execute_reply": "2025-04-24T15:56:59.485606Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.481121Z"
    },
    "papermill": {
     "duration": 0.021715,
     "end_time": "2025-02-28T18:03:41.602304",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.580589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(model_type, backbone_name, checkpoint_path, args):\n",
    "    model = HotelIdModel(args.n_classes, backbone_name)\n",
    "        \n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model = model.to(args.device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073045b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.488119Z",
     "iopub.status.busy": "2025-04-24T15:56:59.487609Z",
     "iopub.status.idle": "2025-04-24T15:56:59.521173Z",
     "shell.execute_reply": "2025-04-24T15:56:59.520004Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.488088Z"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1619311064188,
     "user": {
      "displayName": "Jeom Jin-Ho",
      "photoUrl": "",
      "userId": "00155613517919499503"
     },
     "user_tz": -120
    },
    "id": "appointed-machinery",
    "papermill": {
     "duration": 0.026938,
     "end_time": "2025-02-28T18:03:41.644941",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.618003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "    batch_size = 64\n",
    "    num_workers = 2\n",
    "    n_classes = hotel_id_code_df[\"hotel_id\"].nunique()\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    \n",
    "seed_everything(seed=SEED)\n",
    "\n",
    "test_dataset = HotelImageDataset(test_df, base_transform, data_folder=TEST_DATA_FOLDER)\n",
    "test_loader = DataLoader(test_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97246e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.522491Z",
     "iopub.status.busy": "2025-04-24T15:56:59.522195Z",
     "iopub.status.idle": "2025-04-24T15:56:59.527798Z",
     "shell.execute_reply": "2025-04-24T15:56:59.526880Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.522462Z"
    },
    "papermill": {
     "duration": 0.021454,
     "end_time": "2025-02-28T18:03:41.681969",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.660515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_model(model_type, backbone_name, checkpoint_path, args):\n",
    "    model = HotelIdModel(args.n_classes, backbone_name)\n",
    "    \n",
    "    # Load the checkpoint with map_location\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  \n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    model = model.to(args.device)  # Ensure it's moved to the correct device (CPU/GPU)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "953578b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:56:59.528913Z",
     "iopub.status.busy": "2025-04-24T15:56:59.528608Z",
     "iopub.status.idle": "2025-04-24T15:57:02.325198Z",
     "shell.execute_reply": "2025-04-24T15:57:02.324133Z",
     "shell.execute_reply.started": "2025-04-24T15:56:59.528892Z"
    },
    "papermill": {
     "duration": 2.929055,
     "end_time": "2025-02-28T18:03:44.626305",
     "exception": false,
     "start_time": "2025-02-28T18:03:41.697250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/1137292120.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HotelIdModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=512, out_features=3116, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = get_model(\"classification\", \"resnet34\", \n",
    "                  \"../input/resnet-training/checkpoint-classification-model-resnet34-256x256.pt\", \n",
    "                  args)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755af4dd",
   "metadata": {
    "papermill": {
     "duration": 0.015601,
     "end_time": "2025-02-28T18:03:44.658062",
     "exception": false,
     "start_time": "2025-02-28T18:03:44.642461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56387074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T15:57:02.326940Z",
     "iopub.status.busy": "2025-04-24T15:57:02.326488Z",
     "iopub.status.idle": "2025-04-24T15:57:03.040068Z",
     "shell.execute_reply": "2025-04-24T15:57:03.038763Z",
     "shell.execute_reply.started": "2025-04-24T15:57:02.326902Z"
    },
    "papermill": {
     "duration": 0.487085,
     "end_time": "2025-02-28T18:03:45.161398",
     "exception": false,
     "start_time": "2025-02-28T18:03:44.674313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 747 ms, sys: 140 ms, total: 887 ms\n",
      "Wall time: 688 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc.jpg</td>\n",
       "      <td>24700 108817 73834 18800 203929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id                         hotel_id\n",
       "0  abc.jpg  24700 108817 73834 18800 203929"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = predict_tta(test_loader, model, n_matches=5, tta_transforms=3)\n",
    "# replace classes with hotel_id using mapping created in trainig notebook\n",
    "preds = [[hotel_id_code_map[b] for b in a] for a in preds]\n",
    "# transform array of hotel_ids into string\n",
    "test_df[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\") for l in preds]\n",
    "\n",
    "test_df.to_csv(\"submission.csv\", index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e67b35-aedc-49ca-85c7-b356b9c4c0e8",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1001740-56ce-47b7-ae5a-36ecb5ba21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Prediction function for Gradio\n",
    "def predict_hotel(image):\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert PIL image to numpy and preprocess\n",
    "    img = np.array(image.convert(\"RGB\"))\n",
    "    img = pad_image(img)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # Apply base transform\n",
    "    transformed = base_transform(image=img)[\"image\"]\n",
    "    transformed = transformed.unsqueeze(0).to(args.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(transformed)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        top5 = torch.topk(probs, 5)\n",
    "        indices = top5.indices[0].cpu().numpy()\n",
    "        scores = top5.values[0].cpu().numpy()\n",
    "\n",
    "    # Map to hotel_id labels\n",
    "    hotel_ids = [str(hotel_id_code_map[idx]) for idx in indices]\n",
    "    return {hotel: float(score) for hotel, score in zip(hotel_ids, scores)}\n",
    "\n",
    "\n",
    "# Define the Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict_hotel,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Hotel Room Image\"),\n",
    "    outputs=gr.Label(num_top_classes=5, label=\"Top 5 Predicted Hotels\"),\n",
    "    title=\"Hotel-ID Prediction Demo\",\n",
    "    description=\"This demo uses a ResNet34 model trained to classify hotel rooms based on images. Upload a hotel room photo to see the top 5 predicted hotel IDs. This model helps in combating human trafficking through visual identification.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio app (not supported inside Kaggle UI)\n",
    "demo.launch(share=True)  # Use share=True if running outside Kaggle to get a public URL\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4957097,
     "sourceId": 35150,
     "sourceType": "competition"
    },
    {
     "datasetId": 1027206,
     "sourceId": 3951115,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 96549317,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.439236,
   "end_time": "2025-02-28T18:03:48.432524",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-28T18:03:21.993288",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
