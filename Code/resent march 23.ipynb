{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":35150,"databundleVersionId":4957097,"sourceType":"competition"},{"sourceId":3951115,"sourceType":"datasetVersion","datasetId":1027206},{"sourceId":96549317,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":33.821406,"end_time":"2025-03-19T20:06:22.564645","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-19T20:05:48.743239","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"8ea9432d","cell_type":"markdown","source":"# Intro\nInference notebook for [Hotel-ID starter - classification - traning](https://www.kaggle.com/code/michaln/hotel-id-starter-classification-traning)\n\n","metadata":{"id":"DAY5rHgTm7e8","papermill":{"duration":0.022235,"end_time":"2025-03-19T20:05:59.145418","exception":false,"start_time":"2025-03-19T20:05:59.123183","status":"completed"},"tags":[]}},{"id":"4d692e75","cell_type":"markdown","source":"# Setup","metadata":{"papermill":{"duration":0.020644,"end_time":"2025-03-19T20:05:59.188756","exception":false,"start_time":"2025-03-19T20:05:59.168112","status":"completed"},"tags":[]}},{"id":"0dd5e852","cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.463802Z","iopub.execute_input":"2025-03-24T17:59:07.464182Z","iopub.status.idle":"2025-03-24T17:59:07.468438Z","shell.execute_reply.started":"2025-03-24T17:59:07.464154Z","shell.execute_reply":"2025-03-24T17:59:07.467458Z"},"executionInfo":{"elapsed":16271,"status":"ok","timestamp":1619310548121,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"alleged-legislation","outputId":"c6541e5f-ffb4-4609-d6c6-39784e6a07b1","papermill":{"duration":11.516733,"end_time":"2025-03-19T20:06:10.727259","exception":false,"start_time":"2025-03-19T20:05:59.210526","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":25},{"id":"dc953eaa","cell_type":"markdown","source":"# Imports","metadata":{"id":"cZoSOL9Qm-Yr","papermill":{"duration":0.020585,"end_time":"2025-03-19T20:06:10.768628","exception":false,"start_time":"2025-03-19T20:06:10.748043","status":"completed"},"tags":[]}},{"id":"57ca11ad","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport math","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-24T17:59:07.469831Z","iopub.execute_input":"2025-03-24T17:59:07.470136Z","iopub.status.idle":"2025-03-24T17:59:07.488176Z","shell.execute_reply.started":"2025-03-24T17:59:07.470111Z","shell.execute_reply":"2025-03-24T17:59:07.487236Z"},"executionInfo":{"elapsed":14459,"status":"ok","timestamp":1619310548121,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"expired-matter","papermill":{"duration":0.031884,"end_time":"2025-03-19T20:06:10.821888","exception":false,"start_time":"2025-03-19T20:06:10.790004","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":26},{"id":"fdcfe864","cell_type":"code","source":"from PIL import Image as pil_image\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.490354Z","iopub.execute_input":"2025-03-24T17:59:07.490629Z","iopub.status.idle":"2025-03-24T17:59:07.507760Z","shell.execute_reply.started":"2025-03-24T17:59:07.490605Z","shell.execute_reply":"2025-03-24T17:59:07.506792Z"},"executionInfo":{"elapsed":16003,"status":"ok","timestamp":1619310550014,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"extreme-problem","papermill":{"duration":0.028491,"end_time":"2025-03-19T20:06:10.871353","exception":false,"start_time":"2025-03-19T20:06:10.842862","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":27},{"id":"1df1c407","cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.509554Z","iopub.execute_input":"2025-03-24T17:59:07.509954Z","iopub.status.idle":"2025-03-24T17:59:07.526734Z","shell.execute_reply.started":"2025-03-24T17:59:07.509916Z","shell.execute_reply":"2025-03-24T17:59:07.525672Z"},"executionInfo":{"elapsed":19672,"status":"ok","timestamp":1619310554099,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"angry-domain","papermill":{"duration":0.0289,"end_time":"2025-03-19T20:06:10.921250","exception":false,"start_time":"2025-03-19T20:06:10.892350","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":28},{"id":"ec7b92ff","cell_type":"markdown","source":"# Global","metadata":{"id":"0B00pe7mnBTj","papermill":{"duration":0.020614,"end_time":"2025-03-19T20:06:10.962719","exception":false,"start_time":"2025-03-19T20:06:10.942105","status":"completed"},"tags":[]}},{"id":"07c1f698","cell_type":"code","source":"SEED = 42\nIMG_SIZE = 384\n\nPROJECT_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\"\nTEST_DATA_FOLDER = PROJECT_FOLDER + \"test_images/\"","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.527810Z","iopub.execute_input":"2025-03-24T17:59:07.528093Z","iopub.status.idle":"2025-03-24T17:59:07.543942Z","shell.execute_reply.started":"2025-03-24T17:59:07.528068Z","shell.execute_reply":"2025-03-24T17:59:07.542882Z"},"executionInfo":{"elapsed":589,"status":"ok","timestamp":1619310979015,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"contained-brief","papermill":{"duration":0.029907,"end_time":"2025-03-19T20:06:11.013236","exception":false,"start_time":"2025-03-19T20:06:10.983329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":29},{"id":"642a3969","cell_type":"code","source":"print(os.listdir(PROJECT_FOLDER))","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.544908Z","iopub.execute_input":"2025-03-24T17:59:07.545241Z","iopub.status.idle":"2025-03-24T17:59:07.569079Z","shell.execute_reply.started":"2025-03-24T17:59:07.545207Z","shell.execute_reply":"2025-03-24T17:59:07.568016Z"},"executionInfo":{"elapsed":879,"status":"ok","timestamp":1619310979515,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"PZvmFng7ctO3","outputId":"dce0cc91-8e70-4acc-a0b8-6763ffffd5ca","papermill":{"duration":0.030579,"end_time":"2025-03-19T20:06:11.064812","exception":false,"start_time":"2025-03-19T20:06:11.034233","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"['sample_submission.csv', 'train_images', 'train_masks', 'test_images']\n","output_type":"stream"}],"execution_count":30},{"id":"a1d0963e","cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.570243Z","iopub.execute_input":"2025-03-24T17:59:07.570527Z","iopub.status.idle":"2025-03-24T17:59:07.584151Z","shell.execute_reply.started":"2025-03-24T17:59:07.570502Z","shell.execute_reply":"2025-03-24T17:59:07.583091Z"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1619310981653,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"eastern-content","papermill":{"duration":0.033715,"end_time":"2025-03-19T20:06:11.120143","exception":false,"start_time":"2025-03-19T20:06:11.086428","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":31},{"id":"971f27dd","cell_type":"markdown","source":"# Dataset and transformations","metadata":{"id":"xaJKvvuKnW4k","papermill":{"duration":0.021835,"end_time":"2025-03-19T20:06:11.165014","exception":false,"start_time":"2025-03-19T20:06:11.143179","status":"completed"},"tags":[]}},{"id":"d726b765","cell_type":"code","source":"import albumentations as A\nimport albumentations.pytorch as APT\nimport cv2 \n\nIMG_SIZE = 384\n\n# used for training dataset - augmentations and occlusions\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.75),\n    A.VerticalFlip(p=0.25),\n    A.ShiftScaleRotate(p=0.5, border_mode=cv2.BORDER_CONSTANT),\n    A.OpticalDistortion(p=0.25),\n    A.Perspective(p=0.25),\n    \n    # Add Gaussian Blur\n    A.GaussianBlur(p=0.5, sigma_limit=(0.1, 2.0)),\n\n   # CLAHE to imrove contrast  \n    A.CLAHE(p=0.5),\n\n    \n    # Perspective Transform to imrpove generalizations from different angles \n    A.Perspective(p=0.5, scale=(0.05, 0.15)),\n\n\n    \n    A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//4), # normal coarse dropout\n    \n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions in test data\n\n    A.RandomBrightnessContrast(p=0.75),\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# used for validation dataset - only occlusions\nval_transform = A.Compose([\n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:07.585154Z","iopub.execute_input":"2025-03-24T17:59:07.585420Z","iopub.status.idle":"2025-03-24T17:59:40.782254Z","shell.execute_reply.started":"2025-03-24T17:59:07.585398Z","shell.execute_reply":"2025-03-24T17:59:40.781170Z"},"executionInfo":{"elapsed":1519,"status":"ok","timestamp":1619310984075,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"revolutionary-membership","papermill":{"duration":2.720081,"end_time":"2025-03-19T20:06:13.908275","exception":false,"start_time":"2025-03-19T20:06:11.188194","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/check_version.py:51: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}],"execution_count":32},{"id":"a372ac2f","cell_type":"code","source":"def pad_image(img):\n    w, h, c = np.shape(img)\n    if w > h:\n        pad = int((w - h) / 2)\n        img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=0)\n    else:\n        pad = int((h - w) / 2)\n        img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=0)\n        \n    return img\n\n\ndef open_and_preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = pad_image(img)\n    return cv2.resize(img, (IMG_SIZE, IMG_SIZE))","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.785076Z","iopub.execute_input":"2025-03-24T17:59:40.785504Z","iopub.status.idle":"2025-03-24T17:59:40.791315Z","shell.execute_reply.started":"2025-03-24T17:59:40.785478Z","shell.execute_reply":"2025-03-24T17:59:40.790370Z"},"papermill":{"duration":0.031709,"end_time":"2025-03-19T20:06:13.961286","exception":false,"start_time":"2025-03-19T20:06:13.929577","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":33},{"id":"16422347","cell_type":"code","source":"class HotelImageDataset:\n    def __init__(self, data, transform=None, data_folder=\"train_images/\"):\n        self.data = data\n        self.data_folder = data_folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        record = self.data.iloc[idx]\n        image_path = self.data_folder + record[\"image_id\"]\n        \n        image = np.array(open_and_preprocess_image(image_path)).astype(np.uint8)\n\n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed[\"image\"]\n        \n        return {\n            \"image\" : image,\n        }","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.792726Z","iopub.execute_input":"2025-03-24T17:59:40.793026Z","iopub.status.idle":"2025-03-24T17:59:40.815594Z","shell.execute_reply.started":"2025-03-24T17:59:40.793002Z","shell.execute_reply":"2025-03-24T17:59:40.814570Z"},"executionInfo":{"elapsed":1058,"status":"ok","timestamp":1619310984077,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"found-mouth","papermill":{"duration":0.040625,"end_time":"2025-03-19T20:06:14.022795","exception":false,"start_time":"2025-03-19T20:06:13.982170","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":34},{"id":"f2e27cdf","cell_type":"markdown","source":"# Model","metadata":{"id":"NMDM4PwPnced","papermill":{"duration":0.02149,"end_time":"2025-03-19T20:06:14.066209","exception":false,"start_time":"2025-03-19T20:06:14.044719","status":"completed"},"tags":[]}},{"id":"82813c65","cell_type":"code","source":"class HotelIdModel(nn.Module):\n    def __init__(self, n_classes=100, backbone_name=\"resnet34\"):\n        super(HotelIdModel, self).__init__()\n        \n        self.backbone = timm.create_model(backbone_name, num_classes=n_classes, pretrained=False)\n\n    def forward(self, x):\n        return self.backbone(x)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.816584Z","iopub.execute_input":"2025-03-24T17:59:40.816971Z","iopub.status.idle":"2025-03-24T17:59:40.827010Z","shell.execute_reply.started":"2025-03-24T17:59:40.816938Z","shell.execute_reply":"2025-03-24T17:59:40.825952Z"},"papermill":{"duration":0.031755,"end_time":"2025-03-19T20:06:14.119186","exception":false,"start_time":"2025-03-19T20:06:14.087431","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":35},{"id":"db7ec336","cell_type":"markdown","source":"# Model helper functions","metadata":{"id":"YMZYKhUSneMY","papermill":{"duration":0.023092,"end_time":"2025-03-19T20:06:14.164334","exception":false,"start_time":"2025-03-19T20:06:14.141242","status":"completed"},"tags":[]}},{"id":"717d0689","cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision.transforms as T\n\ndef predict_tta(loader, model, n_matches=5, tta_transforms=3):\n    \"\"\"\n    Perform Test-Time Augmentation (TTA) and return predictions.\n    \n    Parameters:\n        - loader: DataLoader containing test images\n        - model: Trained PyTorch model\n        - n_matches: Number of top predictions to return\n        - tta_transforms: Number of augmentations per image\n    \n    Returns:\n        - preds: TTA-averaged predictions\n    \"\"\"\n    # Automatically detect device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model.to(device)\n    model.eval()\n    preds = []\n\n    with torch.no_grad():\n        for sample in loader:\n            input_images = sample['image'].to(device)\n\n            tta_outputs = []\n            \n            # Original image inference (weighted more)\n            original_output = model(input_images)\n            tta_outputs.append(1.5 * torch.sigmoid(original_output).cpu().numpy())  # Weighting original image\n\n            # Define transformations for TTA\n            transform_list = [\n                lambda x: torch.flip(x, dims=[-1]),  # Horizontal Flip\n                lambda x: T.ColorJitter(brightness=0.1, contrast=0.1)(x),  # Mild brightness/contrast\n                lambda x: T.RandomAffine(degrees=5, translate=(0.05, 0.05))(x),  # Small rotations/translations\n                lambda x: T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))(x)  # Mild blur\n            ]\n            \n            for _ in range(tta_transforms):\n                aug_fn = np.random.choice(transform_list)  # Randomly choose one augmentation\n                aug_input = aug_fn(input_images)\n                outputs = model(aug_input)\n                tta_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n\n            # Average multiple augmented predictions\n            avg_outputs = np.mean(tta_outputs, axis=0)\n            preds.extend(avg_outputs)\n\n    # Get top predictions\n    preds = np.argsort(-np.array(preds), axis=1)[:, :n_matches]\n    return preds\n\n","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.827961Z","iopub.execute_input":"2025-03-24T17:59:40.828231Z","iopub.status.idle":"2025-03-24T17:59:40.841014Z","shell.execute_reply.started":"2025-03-24T17:59:40.828208Z","shell.execute_reply":"2025-03-24T17:59:40.839930Z"},"papermill":{"duration":0.054752,"end_time":"2025-03-19T20:06:14.245869","exception":false,"start_time":"2025-03-19T20:06:14.191117","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":36},{"id":"750d302f","cell_type":"code","source":"import albumentations as A\nimport albumentations.pytorch as APT\nimport cv2 \n\n# used for training dataset - augmentations and occlusions\ntrain_transform = A.Compose([\n    A.RandomCrop(width=64, height=64),\n    A.HorizontalFlip(p=0.75),\n    #A.VerticalFlip(p=0.0),\n    A.ShiftScaleRotate(p=0.5, shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=cv2.INTER_NEAREST, border_mode=cv2.BORDER_CONSTANT),\n    A.OpticalDistortion(p=0.25, distort_limit=0.05, shift_limit=0.01),\n    A.Perspective(p=0.25, scale=(0.05, 0.1)),\n    A.ColorJitter(p=0.75, brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n    A.CoarseDropout(p=0.5, min_holes=1, max_holes=5, \n                    min_height=IMG_SIZE//16, max_height=IMG_SIZE//8,\n                    min_width=IMG_SIZE//16,  max_width=IMG_SIZE//8), # normal coarse dropout\n    \n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions in test data\n    #A.RandomBrightnessContrast(p=0.75),\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# used for validation dataset - only occlusions\nval_transform = A.Compose([\n    A.CoarseDropout(p=0.75, max_holes=1, \n                    min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n                    min_width=IMG_SIZE//4,  max_width=IMG_SIZE//2, \n                    fill_value=(255,0,0)),# simulating occlusions\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])\n\n# no augmentations\nbase_transform = A.Compose([\n    A.ToFloat(),\n    APT.transforms.ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.841855Z","iopub.execute_input":"2025-03-24T17:59:40.842140Z","iopub.status.idle":"2025-03-24T17:59:40.860423Z","shell.execute_reply.started":"2025-03-24T17:59:40.842115Z","shell.execute_reply":"2025-03-24T17:59:40.859318Z"},"papermill":{"duration":0.036509,"end_time":"2025-03-19T20:06:14.319893","exception":false,"start_time":"2025-03-19T20:06:14.283384","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":37},{"id":"9470c6e8","cell_type":"markdown","source":"# Prepare data","metadata":{"id":"AwShW1wXniD6","papermill":{"duration":0.022053,"end_time":"2025-03-19T20:06:14.363139","exception":false,"start_time":"2025-03-19T20:06:14.341086","status":"completed"},"tags":[]}},{"id":"246edda9","cell_type":"code","source":"test_df = pd.DataFrame(data={\"image_id\": os.listdir(TEST_DATA_FOLDER), \"hotel_id\": \"\"}).sort_values(by=\"image_id\")","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.862710Z","iopub.execute_input":"2025-03-24T17:59:40.863051Z","iopub.status.idle":"2025-03-24T17:59:40.895255Z","shell.execute_reply.started":"2025-03-24T17:59:40.863015Z","shell.execute_reply":"2025-03-24T17:59:40.894233Z"},"executionInfo":{"elapsed":3742,"status":"ok","timestamp":1619311036476,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"discrete-right","outputId":"c21ed589-3139-4919-b5d5-07bcf6f1df15","papermill":{"duration":0.0436,"end_time":"2025-03-19T20:06:14.429198","exception":false,"start_time":"2025-03-19T20:06:14.385598","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":38},{"id":"025cc513","cell_type":"code","source":"# code hotel_id mapping created in training notebook by encoding hotel_ids\nhotel_id_code_df = pd.read_csv('../input/resnet-training/hotel_id_code_mapping.csv')\nhotel_id_code_map = hotel_id_code_df.set_index('hotel_id_code').to_dict()[\"hotel_id\"]","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.896183Z","iopub.execute_input":"2025-03-24T17:59:40.896456Z","iopub.status.idle":"2025-03-24T17:59:40.927823Z","shell.execute_reply.started":"2025-03-24T17:59:40.896432Z","shell.execute_reply":"2025-03-24T17:59:40.926845Z"},"papermill":{"duration":0.046428,"end_time":"2025-03-19T20:06:14.496582","exception":false,"start_time":"2025-03-19T20:06:14.450154","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":39},{"id":"ea0dcb18","cell_type":"markdown","source":"# Prepare model","metadata":{"id":"5JPdD2bpnniP","papermill":{"duration":0.020706,"end_time":"2025-03-19T20:06:14.538145","exception":false,"start_time":"2025-03-19T20:06:14.517439","status":"completed"},"tags":[]}},{"id":"a820944d","cell_type":"code","source":"def get_model(model_type, backbone_name, checkpoint_path, args):\n    model = HotelIdModel(args.n_classes, backbone_name)\n        \n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint[\"model\"])\n    model = model.to(args.device)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.928790Z","iopub.execute_input":"2025-03-24T17:59:40.929131Z","iopub.status.idle":"2025-03-24T17:59:40.934122Z","shell.execute_reply.started":"2025-03-24T17:59:40.929096Z","shell.execute_reply":"2025-03-24T17:59:40.933097Z"},"papermill":{"duration":0.031841,"end_time":"2025-03-19T20:06:14.592834","exception":false,"start_time":"2025-03-19T20:06:14.560993","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":40},{"id":"be345074","cell_type":"code","source":"class args:\n    batch_size = 64\n    num_workers = 2\n    n_classes = hotel_id_code_df[\"hotel_id\"].nunique()\n    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    \nseed_everything(seed=SEED)\n\ntest_dataset = HotelImageDataset(test_df, base_transform, data_folder=TEST_DATA_FOLDER)\ntest_loader = DataLoader(test_dataset, num_workers=args.num_workers, batch_size=args.batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.935173Z","iopub.execute_input":"2025-03-24T17:59:40.935512Z","iopub.status.idle":"2025-03-24T17:59:40.973125Z","shell.execute_reply.started":"2025-03-24T17:59:40.935481Z","shell.execute_reply":"2025-03-24T17:59:40.972223Z"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1619311064188,"user":{"displayName":"Jeom Jin-Ho","photoUrl":"","userId":"00155613517919499503"},"user_tz":-120},"id":"appointed-machinery","papermill":{"duration":0.036933,"end_time":"2025-03-19T20:06:14.651348","exception":false,"start_time":"2025-03-19T20:06:14.614415","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":41},{"id":"d2b9fa6b","cell_type":"code","source":"import torch\n\ndef get_model(model_type, backbone_name, checkpoint_path, args):\n    model = HotelIdModel(args.n_classes, backbone_name)\n    \n    # Load the checkpoint with map_location\n    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  \n    \n    model.load_state_dict(checkpoint[\"model\"])\n    model = model.to(args.device)  # Ensure it's moved to the correct device (CPU/GPU)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.974304Z","iopub.execute_input":"2025-03-24T17:59:40.974647Z","iopub.status.idle":"2025-03-24T17:59:40.980457Z","shell.execute_reply.started":"2025-03-24T17:59:40.974616Z","shell.execute_reply":"2025-03-24T17:59:40.979529Z"},"papermill":{"duration":0.031549,"end_time":"2025-03-19T20:06:14.705499","exception":false,"start_time":"2025-03-19T20:06:14.673950","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":42},{"id":"bc5a45ca","cell_type":"code","source":"model = get_model(\"classification\", \"resnet34\", \n                  \"../input/resnet-training/checkpoint-classification-model-resnet34-256x256.pt\", \n                  args)\n\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:40.981381Z","iopub.execute_input":"2025-03-24T17:59:40.981699Z","iopub.status.idle":"2025-03-24T17:59:44.179592Z","shell.execute_reply.started":"2025-03-24T17:59:40.981667Z","shell.execute_reply":"2025-03-24T17:59:44.178510Z"},"papermill":{"duration":3.997955,"end_time":"2025-03-19T20:06:18.725110","exception":false,"start_time":"2025-03-19T20:06:14.727155","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-42-8ceea1be77c6>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n","output_type":"stream"},{"name":"stdout","text":"HotelIdModel(\n  (backbone): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=512, out_features=3116, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":43},{"id":"93ccd27f","cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.021888,"end_time":"2025-03-19T20:06:18.769397","exception":false,"start_time":"2025-03-19T20:06:18.747509","status":"completed"},"tags":[]}},{"id":"9a51c677","cell_type":"code","source":"%%time\n\npreds = predict_tta(test_loader, model, n_matches=5, tta_transforms=3)\n# replace classes with hotel_id using mapping created in trainig notebook\npreds = [[hotel_id_code_map[b] for b in a] for a in preds]\n# transform array of hotel_ids into string\ntest_df[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\") for l in preds]\n\ntest_df.to_csv(\"submission.csv\", index=False)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:59:44.180509Z","iopub.execute_input":"2025-03-24T17:59:44.180763Z","iopub.status.idle":"2025-03-24T17:59:44.962672Z","shell.execute_reply.started":"2025-03-24T17:59:44.180740Z","shell.execute_reply":"2025-03-24T17:59:44.961568Z"},"papermill":{"duration":0.843678,"end_time":"2025-03-19T20:06:19.634726","exception":false,"start_time":"2025-03-19T20:06:18.791048","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"CPU times: user 876 ms, sys: 134 ms, total: 1.01 s\nWall time: 760 ms\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"  image_id                         hotel_id\n0  abc.jpg  24700 18800 308350 108817 40941","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>hotel_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abc.jpg</td>\n      <td>24700 18800 308350 108817 40941</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44}]}